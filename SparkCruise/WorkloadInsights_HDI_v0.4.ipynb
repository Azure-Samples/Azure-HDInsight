{"nbformat_minor": 2, "cells": [{"source": "# Workload Insights Notebook\n\nThis notebook analyzes the denormalized representation of query workload. This denormalized dataset contains the information from applications, queries, plans, and runtime metrics. The plans were also annotated with signatures to identify subexpressions. We hope that the analysis in the notebook helps you in making data-driven decisions.\n\n\n## Features\n1. <a href=#sample>Sample Rows</a>\n2. <a href=#qcount>Query and Operator Counts</a>\n3. <a href=#opfreq>Operator Frequencies</a>\n4. <a href=#cquery>Overlapping Queries</a>\n5. <a href=#csubop>Common Subexpressions Per Operator</a>\n6. <a href=#selviews>Selected Views</a>\n7. <a href=#ss>SparkCruise Savings</a>\n8. <a href=#filterstat>Filter Selectivity</a>\n9. <a href=#exstat>Exchange Operator Statistics</a>\n10. <a href=#recjobs>Recurring Jobs</a>", "cell_type": "markdown", "metadata": {"cell_status": {"execute_time": {"duration": 147.34814453125, "end_time": 1584417525073.1}}, "editable": true, "deletable": true}}, {"source": "## Setup", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "logicalExps = spark.read.format(\"csv\").option(\"sep\", \"|\").option(\"schema\",\"AppID: string (nullable = true), ClusterName: string (nullable = true), Subscription: string (nullable = true), QueryID: integer (nullable = true), AppQueryID: string (nullable = true), OperatorName: string (nullable = true), TreeLevel: integer (nullable = true), ChildCount: integer (nullable = true), StrictSignature: integer (nullable = true), NonStrictSignature: integer (nullable = true), Parameters: string (nullable = true)\").option(\"header\", \"true\").load(\"/peregrine/views/logical_ir.csv\")\nlogicalExps.createOrReplaceTempView(\"LogicalExps\")\nphysicalExps = spark.read.format(\"csv\").option(\"sep\", \"|\").option(\"schema\",\"AppID: string (nullable = true), ClusterName: string (nullable = true), Subscription: string (nullable = true), QueryID: integer (nullable = true), AppQueryID: string (nullable = true), OperatorName: string (nullable = true), TreeLevel: integer (nullable = true), ChildCount: integer (nullable = true), StrictSignature: integer (nullable = true), NonStrictSignature: integer (nullable = true), Parameters: string (nullable = true)\").option(\"header\", \"true\").load(\"/peregrine/views/physical_ir.csv\")\nphysicalExps.createOrReplaceTempView(\"PhysicalExps\")\nanalysisExps = spark.sql(\"SELECT * FROM LogicalExps WHERE ChildCount > 0\")\nanalysisExps.createOrReplaceTempView(\"AnalysisExps\")\nrepeatSubexps = spark.sql(\"SELECT StrictSignature FROM AnalysisExps GROUP BY StrictSignature HAVING COUNT(DISTINCT AppQueryID) > 1\")\nrepeatSubexps.createOrReplaceTempView(\"RepeatSubexps\")", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 2432.85107421875, "end_time": 1593665556870.339}}, "editable": true, "collapsed": false, "deletable": true}}, {"source": "## Sample Rows <a name='sample' /> \nExample of records in intermediate representation.\n", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "%%sql\nSELECT AppID, AppName, AppStartTime, QueryID, QueryWallClockTime, OperatorName, LogicalName, StrictSignature, PRowCount, PExclusiveTime\nFROM PhysicalExps \nWHERE LENGTH(StrictSignature) > 0 AND PExclusiveTime > 0 \nORDER BY rand() \nLIMIT 10", "outputs": [], "metadata": {"diagram": {"chartConfig": {"category": "bar", "aggByBackend": false, "values": [], "yLabel": "", "keys": [], "xLabel": "", "aggregation": "SUM"}, "activateDiagramType": 1, "isSql": false, "isSummary": false, "aggData": {}, "previewData": {"filter": null}}, "cell_status": {"execute_time": {"duration": 874.85400390625, "end_time": 1593665558182.483}}, "editable": true, "collapsed": false, "deletable": true}}, {"source": "## Query and Operator Count <a name='qcount' /> \n\nNumber of queries and operators in workload.", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "%%sql\nSELECT COUNT(DISTINCT AppQueryID) AS QueryCount, COUNT(*) AS OperatorCount, COUNT(DISTINCT OperatorName) AS DistinctOperators\nFROM PhysicalExps", "outputs": [], "metadata": {"diagram": {"chartConfig": {"category": "bar", "aggByBackend": false, "values": ["DistinctOperators"], "yLabel": "DistinctOperators", "keys": [], "xLabel": "", "aggregation": "SUM"}, "activateDiagramType": 1, "isSql": false, "isSummary": false, "aggData": {"DistinctOperators": {"": 13}}, "previewData": {"filter": null}}, "inputCollapsed": true, "cell_status": {"execute_time": {"duration": 375.075927734375, "end_time": 1593665558565.013}}, "deletable": true, "collapsed": false, "editable": true}}, {"source": "## Operator Frequency <a name='opfreq' /> \nFrequency of logical and physical operators in workload.\n", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "%%sql\nSELECT OperatorName, COUNT(*) AS Frequency\nFROM LogicalExps\nGROUP BY OperatorName\nORDER BY Frequency DESC", "outputs": [], "metadata": {"diagram": {"chartConfig": {"category": "pie", "aggByBackend": false, "keys": ["OperatorName"], "isValid": true, "yLabel": "Frequency", "aggregation": "SUM", "values": ["Frequency"], "series": null, "xLabel": "OperatorName", "inValidMsg": null}, "activateDiagramType": 2, "isSql": false, "isSummary": false, "aggData": {"Frequency": {"Sort": 90, "Project": 1589, "Join": 735, "Union": 34, "LocalRelation": 20, "Filter": 933, "LocalLimit": 85, "Window": 30, "LogicalRelation": 868, "Aggregate": 233, "SetDatabaseCommand": 103, "GlobalLimit": 85, "Expand": 10}}, "previewData": {"filter": null}}, "cell_status": {"execute_time": {"duration": 2305.572021484375, "end_time": 1593664721691.412}}, "editable": true, "collapsed": false, "deletable": true}}, {"source": "Frequency of physical operators in workload.\n", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "%%sql\nSELECT OperatorName, COUNT(*) AS Frequency\nFROM PhysicalExps\nGROUP BY OperatorName\nORDER BY Frequency DESC", "outputs": [], "metadata": {"diagram": {"chartConfig": {"category": "pie", "aggByBackend": false, "keys": ["OperatorName"], "isValid": true, "aggregation": "SUM", "values": ["Frequency"], "yLabel": "Frequency", "xLabel": "OperatorName", "inValidMsg": null}, "activateDiagramType": 2, "isSql": false, "isSummary": false, "aggData": {"Frequency": {"FileSourceScanExec": 605, "LocalTableScanExec": 20, "FilterExec": 648, "ProjectExec": 1256, "UnionExec": 33, "ShuffledHashJoinExec": 123, "SortExec": 196, "ShuffleExchangeExec": 581, "WholeStageCodegenExec": 1265, "BroadcastExchangeExec": 323, "ExpandExec": 10, "SortMergeJoinExec": 90, "BroadcastNestedLoopJoinExec": 19, "CollectLimitExec": 5, "BroadcastHashJoinExec": 443, "ReusedExchangeExec": 202, "HashAggregateExec": 451, "InputAdapter": 1158, "TakeOrderedAndProjectExec": 80, "ExecutedCommandExec": 103, "WindowExec": 30}}, "previewData": {"filter": null}}, "inputCollapsed": true, "cell_status": {"execute_time": {"duration": 2439.66796875, "end_time": 1593664725353.642}}, "deletable": true, "collapsed": false, "editable": true}}, {"source": "### Overlapping queries <a name='cquery' /> \nQueries with overlapping computations.\n", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "queryCountQuery = \"\"\"\nSELECT COUNT(DISTINCT AppQueryID) AS QueryCount \nFROM AnalysisExps\"\"\"\nqueryCount = spark.sql(queryCountQuery)\nqueryCount.createOrReplaceTempView(\"QueryCount\")\n\nqueriesWithRepeatQuery = \"\"\"\nSELECT COUNT(DISTINCT AppQueryID) AS QueriesWithOneOverlap\nFROM AnalysisExps\nWHERE StrictSignature IN \n( SELECT StrictSignature\nFROM RepeatSubexps )\"\"\"\nqueriesWithRepeat = spark.sql(queriesWithRepeatQuery)\nqueriesWithRepeat.createOrReplaceTempView(\"QueriesWithRepeat\")\n\nqueriesWithTwoRepeatsQuery = \"\"\"\nSELECT COUNT(*) AS QueriesWithTwoOverlaps FROM (\nSELECT AppQueryID, COUNT(*) AS Repeats \nFROM AnalysisExps\nWHERE StrictSignature IN \n( SELECT StrictSignature\nFROM RepeatSubexps )\nGROUP BY AppQueryID\nHAVING Repeats > 1\nORDER BY Repeats DESC)\"\"\"\nqueriesWithTwoRepeats = spark.sql(queriesWithTwoRepeatsQuery)\nqueriesWithTwoRepeats.createOrReplaceTempView(\"QueriesWithTwoRepeats\")", "outputs": [], "metadata": {"diagram": {"chartConfig": {"category": "line", "aggByBackend": false, "keys": ["QueryCount", "QueriesWithOneOverlap", "QueriesWithTwoOverlaps"], "isValid": false, "aggregation": "SUM", "values": [], "yLabel": "", "xLabel": "QueryCount,QueriesWithOneOverlap,QueriesWithTwoOverlaps", "inValidMsg": "At least one value column is required!"}, "activateDiagramType": 1, "isSql": false, "isSummary": false, "aggData": {}, "previewData": {"filter": null}}, "inputCollapsed": true, "cell_status": {"execute_time": {"duration": 760.51904296875, "end_time": 1593664726270.094}}, "deletable": true, "collapsed": false, "editable": true}}, {"execution_count": null, "cell_type": "code", "source": "%%sql\nSELECT *, CAST((QueriesWithOneOverlap/QueryCount)*100 AS Decimal(38,2)) AS OverlapPercent \nFROM QueryCount AS R1, QueriesWithRepeat AS R2, QueriesWithTwoRepeats AS R3", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 166.10205078125, "end_time": 1593664726440.694}}, "collapsed": false}}, {"source": "## Overlapping Computations <a name='csubop' /> \n\nOverlapping computations per operator.\n", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "opFreqQuery = \"\"\"\nSELECT OperatorName, COUNT(*) AS Total\nFROM AnalysisExps\nGROUP BY OperatorName\nORDER BY Total DESC\"\"\"\nopFreq = spark.sql(opFreqQuery)\nopFreq.createOrReplaceTempView(\"OpFreq\")\n\nopRepeatSubexpQuery = \"\"\"\nSELECT OperatorName, COUNT(*) AS Repeats\nFROM AnalysisExps\nWHERE StrictSignature IN \n( SELECT StrictSignature\nFROM RepeatSubexps )\nGROUP BY OperatorName\nORDER BY Repeats DESC\"\"\"\nopRepeatSubexp = spark.sql(opRepeatSubexpQuery)\nopRepeatSubexp.createOrReplaceTempView(\"OpRepeatSubexp\")\n\nopDistinctRepeatQuery = \"\"\"\nSELECT OperatorName, COUNT(*) AS DistinctRepeats\nFROM ( SELECT DISTINCT OperatorName, StrictSignature \nFROM AnalysisExps\nWHERE StrictSignature IN \n( SELECT StrictSignature\nFROM RepeatSubexps ))\nGROUP BY OperatorName\nORDER BY DistinctRepeats DESC\"\"\"\nopDistinctRepeat = spark.sql(opDistinctRepeatQuery)\nopDistinctRepeat.createOrReplaceTempView(\"OpDistinctRepeat\")", "outputs": [], "metadata": {"diagram": {"chartConfig": {"category": "bar", "aggByBackend": false, "keys": ["OperatorName"], "isValid": true, "aggregation": "SUM", "values": ["Total", "Repeats"], "yLabel": "Total,Repeats", "xLabel": "OperatorName", "inValidMsg": null}, "activateDiagramType": 2, "isSql": false, "isSummary": false, "aggData": {"Repeats": {"Aggregate": 26, "Filter": 513, "Project": 393, "Join": 48}, "Total": {"Aggregate": 233, "Filter": 933, "Project": 1589, "Join": 735}}, "previewData": {"filter": null}}, "inputCollapsed": true, "cell_status": {"execute_time": {"duration": 1294.239990234375, "end_time": 1593665528156.392}}, "deletable": true, "collapsed": false, "editable": true}}, {"execution_count": null, "cell_type": "code", "source": "%%sql\nSELECT R1.OperatorName, Total, Repeats, DistinctRepeats, CAST(Repeats/DistinctRepeats AS Decimal(38,2)) AS AvgRepFrequency, CAST((Repeats/Total)*100 AS Decimal(38,2)) AS RepeatPercent  \nFROM OpFreq AS R1, OpRepeatSubexp AS R2, OpDistinctRepeat AS R3\nWHERE R1.OperatorName = R2.OperatorName AND R2.OperatorName = R3.OperatorName\nORDER BY RepeatPercent DESC", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 769.869873046875, "end_time": 1593665529433.968}}, "collapsed": false}}, {"source": "## Selected Views <a name='selviews' /> \nPer operator summary of selected views.", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "selViews = spark.read.format(\"csv\").option(\"sep\", \"|\").option(\"schema\",\"AppID: string (nullable = true), ClusterName: string (nullable = true), Subscription: string (nullable = true), QueryID: integer (nullable = true), AppQueryID: string (nullable = true), OperatorName: string (nullable = true), TreeLevel: integer (nullable = true), ChildCount: integer (nullable = true), StrictSignature: integer (nullable = true), NonStrictSignature: integer (nullable = true), Parameters: string (nullable = true)\").option(\"header\", \"true\").load(\"/peregrine/views/views.csv\")\nselViews.createOrReplaceTempView(\"SelViews\")\nviews = spark.sql(\"SELECT DISTINCT StrictSignature FROM SelViews\")\nviews.createOrReplaceTempView(\"Views\")", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 1319.8837890625, "end_time": 1593665531816.984}}, "collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "distinctViewsQuery = \"\"\"\nSELECT P.LogicalName AS LogicalName, COUNT(DISTINCT P.StrictSignature) AS ViewCount\nFROM Views V, PhysicalExps P\nWHERE V.StrictSignature = P.StrictSignature \nGROUP BY P.LogicalName\nORDER BY ViewCount DESC\"\"\"\ndistinctViews = spark.sql(distinctViewsQuery)\ndistinctViews.createOrReplaceTempView(\"DistinctViews\")\n\nviewSubexprsOpsQuery = \"\"\"\nSELECT P.LogicalName AS LogicalName, COUNT(*) AS ViewRepeats\nFROM Views V, PhysicalExps P\nWHERE V.StrictSignature = P.StrictSignature \nGROUP BY P.LogicalName\nORDER BY ViewRepeats DESC\"\"\"\nviewSubexprsOps = spark.sql(viewSubexprsOpsQuery)\nviewSubexprsOps.createOrReplaceTempView(\"ViewSubexprsOps\")", "outputs": [], "metadata": {"diagram": {"chartConfig": {"category": "bar", "aggByBackend": false, "values": ["ViewCount"], "yLabel": "ViewCount", "keys": ["LogicalName"], "xLabel": "LogicalName", "aggregation": "SUM"}, "activateDiagramType": 2, "isSql": false, "isSummary": false, "aggData": {"ViewCount": {"Aggregate": 4, "Filter": 18, "Project": 8, "Join": 12}}, "previewData": {"filter": null}}, "inputCollapsed": true, "cell_status": {"execute_time": {"duration": 1294.304931640625, "end_time": 1593665534662.815}}, "deletable": true, "collapsed": false, "editable": true}}, {"execution_count": null, "cell_type": "code", "source": "%%sql\nSELECT X.LogicalName, ViewCount, ViewRepeats\nFROM DistinctViews AS X, ViewSubexprsOps AS Y\nWHERE X.LogicalName = Y.LogicalName", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 1329.829833984375, "end_time": 1593665537600.952}}, "collapsed": false}}, {"source": "## SparkCruise Savings <a name='ss' /> \nPotential savings per view.\n", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "%%sql\nSELECT LogicalName, NumOccurrences, AvgSerialTime_ms, AvgRowCount, AvgRowLength_bytes\nFROM (\nSELECT P.LogicalName AS LogicalName, P.StrictSignature AS Id, COUNT(*) AS NumOccurrences, AVG(PSerialTime) AS AvgSerialTime_ms, AVG(PRowCount) AS AvgRowCount, AVG(AvgRowLength) AS AvgRowLength_bytes\nFROM Views V, PhysicalExps P\nWHERE V.StrictSignature = P.StrictSignature\nGROUP BY P.LogicalName, P.StrictSignature)", "outputs": [], "metadata": {"diagram": {"chartConfig": {"category": "bar", "aggByBackend": false, "values": ["AvgSerialTime"], "yLabel": "AvgSerialTime", "keys": ["AvgRowCount"], "xLabel": "AvgRowCount", "aggregation": "SUM"}, "activateDiagramType": 1, "isSql": false, "isSummary": false, "aggData": {"AvgSerialTime": {"506811.728": 84115.256}}, "previewData": {"filter": null}}, "inputCollapsed": true, "cell_status": {"execute_time": {"duration": 858.774169921875, "end_time": 1593665538514.189}}, "deletable": true, "collapsed": false, "editable": true}}, {"source": "## Filter Selectivity <a name='filterstat' /> \nSelectivity of filters.\n", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "%%sql -o filterSel\n\nSELECT F.AppQueryID, F.OperatorName AS FilterOp, F.RowCount AS PassCount, T.OperatorName AS ScanOp, T.RowCount AS TotalCount, CAST(F.RowCount/T.RowCount AS Decimal(38, 5)) AS FilterSel\nFROM PhysicalExps F, PhysicalExps T \nWHERE F.AppQueryID = T.AppQueryID AND\nF.OperatorName = 'FilterExec' AND \nT.ParentID = F.OperatorID AND\nT.RowCount > 0 AND \nT.ChildCount = 0\nORDER BY FilterSel", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 2330.943115234375, "end_time": 1593665542369.796}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "%%local\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\n# CDF\nfilterSel['pdf'] = filterSel['FilterSel']/sum(filterSel['FilterSel'])\nfilterSel['ecdf'] = (filterSel['pdf'].cumsum())\nax = filterSel.plot(x = 'FilterSel', y = 'ecdf', grid = True)\nax.set_xlabel(\"Filter Selectivity\")\nax.set_ylabel(\"CDF\")\nax.set_xlim(0, 1)\nax.set_ylim(0, 1)", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 888.823974609375, "end_time": 1593665543298.182}}, "collapsed": false}}, {"source": "## Exchange <a name='exstat' /> \nHow many rows are shuffled in real-world Spark workloads?", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "def getBucket(rowCount):\n    rows = int(rowCount)\n    if rows <=1:\n        return \"a. 0-1\"\n    elif (rows > 1 and rows <= 1e3):\n        return \"b. 1-1k\"\n    elif (rows > 1e3 and rows <= 1e5):\n        return \"c. 1k-100k\"\n    elif (rows > 1e5 and rows <= 1e6):\n        return \"d. 100k-1M\"\n    elif (rows > 1e6 and rows <= 1e8):\n        return \"e. 1M-100M\"\n    elif (rows > 1e8 and rows <=  1e9):\n        return \"f. 100M-1B\"\n    else:\n        return \"g. >1B\"\n\nspark.udf.register(\"getBucket\", getBucket)\nexBucketQuery = \"\"\" SELECT Bucket AS RowCountBucket, CAST(AVG(MB) AS Decimal(38,2)) AS AvgDataSizeInMB, CAST(MAX(MB) AS Decimal(38,2)) AS MaxDataSizeInMB, COUNT(*) AS Count\nFROM (\nSELECT getBucket(PRowCount) AS Bucket, Bytes/(1024.0*1024) AS MB\nFROM PhysicalExps\nWHERE PRowCount > 0 AND Bytes > 0 AND OperatorName LIKE '%ShuffleExchangeExec%')\nGROUP BY Bucket\nORDER BY RowCountBucket\n\"\"\"\nexBucket = spark.sql(exBucketQuery)\nexBucket.show(100, False)\nexBucket.createOrReplaceTempView(\"ExBucket\")", "outputs": [], "metadata": {"diagram": {"chartConfig": {"category": "bar", "aggByBackend": false, "keys": ["RowCountBucket"], "isValid": true, "aggregation": "SUM", "values": ["Count"], "yLabel": "Count", "xLabel": "RowCountBucket", "inValidMsg": null}, "activateDiagramType": 2, "isSql": false, "isSummary": false, "aggData": {"Count": {"3. 1k-100k": 81, "6. 100M-1B": 1, "5. 1M-100M": 169, "2. 1-1k": 73, "4. 100k-1M": 80}}, "previewData": {"filter": null}}, "inputCollapsed": true, "cell_status": {"execute_time": {"duration": 3367.154052734375, "end_time": 1593665547942.685}}, "deletable": true, "collapsed": false, "editable": true}}, {"execution_count": null, "cell_type": "code", "source": "%%sql -o exBuckets\nSELECT * \nFROM ExBucket", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 830.60888671875, "end_time": 1593665548808.813}}, "collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "%%local\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\nexBuckets['RCBucketLabels'] = exBuckets['RowCountBucket'].str[3:]\n\nax = exBuckets.plot.bar(x='RCBucketLabels', y='Count', rot=0)\nax.set_xlabel(\"Number of rows in exchange\")\nax.set_ylabel(\"Frequency\")", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 395.66796875, "end_time": 1593665549330.06}}, "collapsed": false}}, {"source": "## Recurring jobs <a name='recjobs' /> \nRecurring jobs share same non-strict signature at the root level. To capture temporal patterns, we can take the intersection of the result set for a few consecutive days and then split the intesection set in hourly, daily repeat patterns based on the AppSubmitTime value.", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "%%sql\nSELECT Subscription, NonStrictSignature, COUNT(*) AS Count\nFROM AnalysisExps\nWHERE TreeLevel = 0 AND LENGTH(NonStrictSignature) > 0\nGROUP BY Subscription, NonStrictSignature\nHAVING COUNT(*) > 1\nORDER BY Count DESC", "outputs": [], "metadata": {"diagram": {"chartConfig": {"category": "bar", "aggByBackend": false, "values": ["Count"], "yLabel": "Count", "keys": ["Subscription"], "xLabel": "Subscription", "aggregation": "SUM"}, "activateDiagramType": 1, "isSql": false, "isSummary": false, "aggData": {"Count": {"test": 2}}, "previewData": {"filter": null}}, "inputCollapsed": true, "cell_status": {"execute_time": {"duration": 2447.49609375, "end_time": 1593665552970.298}}, "deletable": true, "collapsed": false, "editable": true}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark3", "name": "pyspark3kernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python3", "name": "pyspark3", "codemirror_mode": {"version": 3, "name": "python"}}, "saveOutput": true}}